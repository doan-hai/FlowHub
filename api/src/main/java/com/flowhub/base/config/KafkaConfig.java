package com.flowhub.base.config;

import java.util.HashMap;
import java.util.Map;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.IsolationLevel;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;
import org.springframework.kafka.listener.ContainerProperties;
import org.springframework.kafka.support.DefaultKafkaHeaderMapper;
import org.springframework.kafka.support.KafkaHeaderMapper;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;

/**
 * **C·∫•u h√¨nh Kafka (`KafkaConfig`)**
 *
 * <p>L·ªõp n√†y ch·ªãu tr√°ch nhi·ªám c·∫•u h√¨nh Kafka cho ·ª©ng d·ª•ng. N√≥ bao g·ªìm c√°c thi·∫øt l·∫≠p cho
 * **consumer**, **producer**, **Kafka template** v√† **header mapper**.</p>
 * <p>
 * **üìå Ch·ª©c nƒÉng ch√≠nh:**
 * <ul>
 *   <li>‚úÖ C·∫•u h√¨nh consumer ƒë·ªÉ l·∫Øng nghe c√°c tin nh·∫Øn t·ª´ Kafka.</li>
 *   <li>‚úÖ C·∫•u h√¨nh producer ƒë·ªÉ g·ª≠i tin nh·∫Øn ƒë·∫øn Kafka.</li>
 *   <li>‚úÖ C·∫•u h√¨nh KafkaTemplate ƒë·ªÉ h·ªó tr·ª£ g·ª≠i tin nh·∫Øn.</li>
 *   <li>‚úÖ C·∫•u h√¨nh Kafka header mapper ƒë·ªÉ √°nh x·∫° header c·ªßa tin nh·∫Øn.</li>
 *   <li>‚úÖ C·∫•u h√¨nh ThreadPool ƒë·ªÉ x·ª≠ l√Ω c√°c consumer.</li>
 * </ul>
 *
 * @author haidv
 * @version 1.0
 */
@EnableKafka
@Configuration
public class KafkaConfig {

  @Value("${custom.properties.kafka.bootstrap-servers}")
  private String bootstrapServerUrl;

  @Value("${custom.properties.messaging.kafka.consumer.batch}")
  private boolean isBatchConsumerNapasTranfer;

  @Value("${custom.properties.kafka.comsumer.max.timeout}")
  private int consumerTimeout;

  @Value("${custom.properties.messaging.kafka.consumer.number.of.message.in.batch}")
  private int maxBatchRecordNapasTranfer;

  @Value("${custom.properties.messaging.consumer.pool.size}")
  private int kafkaConsumerThreadPoolSize;

  @Value("${custom.properties.graceful.shutdown.messaging.consumer.wait.time.max}")
  private int waitTimeMax;

  @Value("${custom.properties.messaging.consumer.pool.thread.name.prefix}")
  private String threadNamePrefix;

  /**
   * **T·∫°o ThreadPool cho Kafka Consumer**
   *
   * <p>Ph∆∞∆°ng th·ª©c n√†y t·∫°o m·ªôt `ThreadPoolTaskExecutor` ƒë·ªÉ qu·∫£n l√Ω c√°c lu·ªìng x·ª≠ l√Ω Kafka
   * consumer.</p>
   *
   * @return M·ªôt `ThreadPoolTaskExecutor` ƒë·ªÉ x·ª≠ l√Ω c√°c consumer.
   */
  @Bean(name = "kafkaConsumerThreadPool")
  public ThreadPoolTaskExecutor messageProcessorExecutor() {
    ThreadPoolTaskExecutor exec = new ThreadPoolTaskExecutor();
    exec.setCorePoolSize(kafkaConsumerThreadPoolSize);
    exec.setMaxPoolSize(kafkaConsumerThreadPoolSize);
    exec.setAllowCoreThreadTimeOut(true);
    exec.setWaitForTasksToCompleteOnShutdown(true);
    exec.setAwaitTerminationSeconds(waitTimeMax);
    exec.setThreadNamePrefix(threadNamePrefix);
    return exec;
  }

  /**
   * **C·∫•u h√¨nh Kafka Consumer**
   *
   * <p>Ph∆∞∆°ng th·ª©c n√†y t·∫°o m·ªôt `ConsumerFactory` ch·ª©a c√°c c·∫•u h√¨nh c·∫ßn thi·∫øt ƒë·ªÉ consumer c√≥ th·ªÉ
   * l·∫Øng nghe Kafka.</p>
   *
   * @return M·ªôt `ConsumerFactory` cho Kafka Consumer.
   */
  @Bean
  public ConsumerFactory<String, String> consumerFactory() {
    Map<String, Object> props = new HashMap<>();
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServerUrl);
    props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, maxBatchRecordNapasTranfer);
    props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
    props.put(ConsumerConfig.DEFAULT_ISOLATION_LEVEL, IsolationLevel.READ_COMMITTED);
    props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, consumerTimeout);
    props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
    return new DefaultKafkaConsumerFactory<>(props);
  }

  /**
   * **C·∫•u h√¨nh Kafka Listener Container Factory**
   *
   * <p>Ph∆∞∆°ng th·ª©c n√†y t·∫°o m·ªôt `ConcurrentKafkaListenerContainerFactory` ƒë·ªÉ l·∫Øng nghe v√† x·ª≠ l√Ω tin
   * nh·∫Øn t·ª´ Kafka.</p>
   *
   * @return M·ªôt `ConcurrentKafkaListenerContainerFactory` cho Kafka Consumer.
   */
  @Bean("kafkaListenerContainerFactory")
  public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory<String, String> factory =
        new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory());
    factory.setBatchListener(isBatchConsumerNapasTranfer);
    factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE);
    factory.getContainerProperties().setListenerTaskExecutor(messageProcessorExecutor());
    return factory;
  }

  /**
   * **C·∫•u h√¨nh Header Mapper cho Kafka**
   *
   * <p>Ph∆∞∆°ng th·ª©c n√†y t·∫°o m·ªôt `KafkaHeaderMapper` ƒë·ªÉ √°nh x·∫° c√°c header c·ªßa tin nh·∫Øn Kafka.</p>
   *
   * @return M·ªôt `KafkaHeaderMapper` ƒë·ªÉ √°nh x·∫° header.
   */
  @Bean("kafkaBinderHeaderMapper")
  public KafkaHeaderMapper kafkaBinderHeaderMapper() {
    DefaultKafkaHeaderMapper mapper = new DefaultKafkaHeaderMapper();
    mapper.setMapAllStringsOut(true);
    return mapper;
  }

  /**
   * **C·∫•u h√¨nh Kafka Producer**
   *
   * <p>Ph∆∞∆°ng th·ª©c n√†y t·∫°o m·ªôt `ProducerFactory` ch·ª©a c√°c c·∫•u h√¨nh c·∫ßn thi·∫øt ƒë·ªÉ producer c√≥ th·ªÉ
   * g·ª≠i tin nh·∫Øn ƒë·∫øn Kafka.</p>
   *
   * @return M·ªôt `ProducerFactory` cho Kafka Producer.
   */
  @Bean
  public ProducerFactory<Object, Object> producerFactory() {
    Map<String, Object> configProps = new HashMap<>();
    configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServerUrl);
    configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    configProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, false);
    return new DefaultKafkaProducerFactory<>(configProps);
  }

  /**
   * **C·∫•u h√¨nh KafkaTemplate**
   *
   * <p>Ph∆∞∆°ng th·ª©c n√†y t·∫°o m·ªôt `KafkaTemplate` ƒë·ªÉ h·ªó tr·ª£ g·ª≠i tin nh·∫Øn Kafka.</p>
   *
   * @return M·ªôt `KafkaTemplate` ƒë·ªÉ g·ª≠i tin nh·∫Øn.
   */
  @Bean
  public KafkaTemplate<Object, Object> kafkaTemplate() {
    return new KafkaTemplate<>(producerFactory());
  }
}
